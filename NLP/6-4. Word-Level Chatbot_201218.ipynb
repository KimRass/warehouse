{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgyWaYYUZMAW"
   },
   "source": [
    "# 단어 레벨 챗봇 (함수형 API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-OZb2-8Zb99"
   },
   "source": [
    "이 챗봇은 데이터를 매우 적게 학습하였습니다. 더 많은 데이터를 학습할수록 일반화 능력이 높아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "CT-_Zm6lXyku"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import MeCab\n",
    "import urllib\n",
    "\n",
    "class Mecab:\n",
    "    def pos(self, text):\n",
    "        p = re.compile(\".+\\t[A-Z]+\")\n",
    "        return [tuple(p.match(line).group().split(\"\\t\")) for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n",
    "    \n",
    "    def morphs(self, text):\n",
    "        p = re.compile(\".+\\t[A-Z]+\")\n",
    "        return [p.match(line).group().split(\"\\t\")[0] for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n",
    "    \n",
    "    def nouns(self, text):\n",
    "        p = re.compile(\".+\\t[A-Z]+\")\n",
    "        temp = [tuple(p.match(line).group().split(\"\\t\")) for line in MeCab.Tagger().parse(text).splitlines()[:-1]]\n",
    "        nouns=[]\n",
    "        for word in temp:\n",
    "            if word[1] in [\"NNG\", \"NNP\", \"NNB\", \"NNBC\", \"NP\", \"NR\"]:\n",
    "                nouns.append(word[0])\n",
    "        return nouns\n",
    "    \n",
    "mcb = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/data/master/ChatbotData%20.csv\", filename=\"ChatbotData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_iLXSDtX3Ny"
   },
   "outputs": [],
   "source": [
    "# 태그 단어\n",
    "PAD = \"<PAD>\"   # 패딩\n",
    "STA = \"<SOS>\"     # 시작\n",
    "END = \"<EOS>\"       # 끝\n",
    "UNK = \"<UNK>\"       # 없는 단어(Out of Vocabulary)\n",
    "\n",
    "# 태그 인덱스\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "# 데이터 타입\n",
    "enc_input  = 0\n",
    "dec_input  = 1\n",
    "dec_output = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_iLXSDtX3Ny"
   },
   "outputs": [],
   "source": [
    "# 한 문장에서 단어 시퀀스의 최대 개수\n",
    "max_len = 30\n",
    "# 임베딩 벡터 차원\n",
    "emb_dim = 100\n",
    "\n",
    "# LSTM 히든레이어 차원\n",
    "h_size = 128\n",
    "\n",
    "# 정규 표현식 필터\n",
    "RE_FILTER = re.compile(r\"[.,!?\\'':;~()]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "o_iLXSDtX3Ny"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ChatbotData .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "o_iLXSDtX3Ny"
   },
   "outputs": [],
   "source": [
    "Qs = data[\"Q\"].tolist()[:100]\n",
    "As = data[\"A\"].tolist()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPiHbiqPYNx8"
   },
   "outputs": [],
   "source": [
    "# # 형태소분석 함수\n",
    "# def pos_tag(sentences):\n",
    "    \n",
    "#     # KoNLPy 형태소분석기 설정\n",
    "#     tagger = Okt()\n",
    "    \n",
    "#     # 문장 품사 변수 초기화\n",
    "#     sentences_pos = []\n",
    "    \n",
    "#     # 모든 문장 반복\n",
    "#     for sentence in sentences:\n",
    "#         # 특수기호 제거\n",
    "#         sentence = re.sub(RE_FILTER, \"\", sentence)\n",
    "        \n",
    "#         # 배열인 형태소분석의 출력을 띄어쓰기로 구분하여 붙임\n",
    "#         sentence = \" \".join(tagger.morphs(sentence))\n",
    "#         sentences_pos.append(sentence)\n",
    "        \n",
    "#     return sentences_pos\n",
    "\n",
    "# # 형태소분석 수행\n",
    "# Q = pos_tag(Q)\n",
    "# A = pos_tag(A)\n",
    "\n",
    "# # 형태소분석으로 변환된 챗봇 데이터 출력\n",
    "# for i in range(10):\n",
    "#     print('Q : ' + Q[i])\n",
    "#     print('A : ' + A[i])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "h1iJrUckYSK2"
   },
   "outputs": [],
   "source": [
    "# # 질문과 대답 문장들을 하나로 합침\n",
    "# sentences = []\n",
    "# sentences.extend(Qs)\n",
    "# sentences.extend(As)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "QAs = Qs + As\n",
    "\n",
    "tkn = tf.keras.preprocessing.text.Tokenizer(oov_token=\"UNK\")\n",
    "tkn.fit_on_texts(QAs)\n",
    "\n",
    "word2idx = tkn.word_index\n",
    "idx2word = tkn.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태그 단어\n",
    "PAD = \"<PAD>\"   # 패딩\n",
    "STA = \"<SOS>\"     # 시작\n",
    "END = \"<EOS>\"       # 끝\n",
    "UNK = \"<UNK>\"       # 없는 단어(Out of Vocabulary)\n",
    "\n",
    "# 태그 인덱스\n",
    "PAD_INDEX = 0\n",
    "STA_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3박4일 놀러가고 싶다'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QAs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[63, 64, 31]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkn.texts_to_sequences(['3박4일 놀러가고 싶다'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "88QFC-JXYdaq"
   },
   "outputs": [],
   "source": [
    "max_len = 30\n",
    "# 문장을 인덱스로 변환\n",
    "def convert_text_to_idx(sents, word2idx, type): \n",
    "    \n",
    "    sents_idx = []\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for sent in sents:\n",
    "        sent_idx = []\n",
    "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
    "        if type == \"dec_input\":\n",
    "            sent_idx.extend([word2idx[\"<SOS>\"]])\n",
    "        # 문장의 단어들을 띄어쓰기로 분리\n",
    "        for word in sent.split():\n",
    "            # 사전에 있는 단어면 해당 인덱스를 추가\n",
    "            if word2idx[word] != None:\n",
    "                sent_idx.append(word2idx[word])\n",
    "            # 사전에 없는 단어면 UNK 인덱스를 추가\n",
    "            else:\n",
    "                sent_idx.append(word2idx[\"<UNK>\"])\n",
    "\n",
    "        # 최대 길이 검사\n",
    "        if type == \"dec_output\":\n",
    "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
    "            # 문장의 최대 길이 이상일 경우\n",
    "            if len(sent_idx) >= max_len:\n",
    "                sent_idx = sent_idx[:max_len-1] + [word2idx[\"<EOS>\"]]\n",
    "            else:\n",
    "                sent_idx += [word2idx[\"<EOS>\"]]\n",
    "        else:\n",
    "            if len(sent_idx) > max_len:\n",
    "                sent_idx = sent_idx[:max_len]\n",
    "            \n",
    "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
    "        sent_idx += (max_len - len(sent_idx)) * [word2idx[\"<PAD>\"]]\n",
    "        \n",
    "        # 문장의 인덱스 배열을 추가\n",
    "        sents_idx.append(sent_idx)\n",
    "\n",
    "    return np.array(sents_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "YPmuWDxOYfRi",
    "outputId": "fe13c520-635d-4953-f64f-e609bb438ab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2775, 20868,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인코더 입력 인덱스 변환\n",
    "x_encoder = convert_text_to_idx(Qs, word_to_index, \"enc_input\")\n",
    "\n",
    "# 첫 번째 인코더 입력 출력 (12시 땡)\n",
    "x_encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "AAoOMv89YgqV",
    "outputId": "ef4e6a0e-4b0b-4e0f-b06a-ba4895477715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1, 19616,  5970,  1688,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더 입력 인덱스 변환\n",
    "x_decoder = convert_text_to_idx(As, word_to_index, \"dec_input\")\n",
    "\n",
    "# 첫 번째 디코더 입력 출력 (START 하루 가 또 가네요)\n",
    "x_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "aHso80jXYhlc",
    "outputId": "be3a6965-6be5-4682-e7d6-78d8ac6e3f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19616,  5970,  1688,     2,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더 목표 인덱스 변환\n",
    "y_decoder = convert_text_to_idx(As, word_to_index, \"dec_output\")\n",
    "\n",
    "# 첫 번째 디코더 목표 출력 (하루 가 또 가네요 END)\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "Ahr_oCPYYkBJ",
    "outputId": "00bc2fbe-1562-496e-c51d-f56014b01793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원핫인코딩 초기화\n",
    "one_hot_data = np.zeros((len(y_decoder), max_len, len(words)))\n",
    "\n",
    "# 디코더 목표를 원핫인코딩으로 변환\n",
    "# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
    "for i, sequence in enumerate(y_decoder):\n",
    "    for j, index in enumerate(sequence):\n",
    "        one_hot_data[i, j, index] = 1\n",
    "\n",
    "# 디코더 목표 설정\n",
    "y_decoder = one_hot_data\n",
    "\n",
    "# 첫 번째 디코더 목표 출력\n",
    "y_decoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "o3gCejxdYnZZ",
    "outputId": "167a6182-a136-46e4-f5d7-11dbfba83c50"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-60bac7429db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 입력 문장의 인덱스 시퀀스를 입력으로 받음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mencoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 임베딩 레이어\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#--------------------------------------------\n",
    "# 훈련 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "enc_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "encoder_outputs = layers.Embedding(len(words), emb_dim)(enc_inputs)\n",
    "\n",
    "# return_state가 True면 상태값 리턴\n",
    "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
    "encoder_outputs, state_h, state_c = layers.LSTM(h_size,\n",
    "                                                dropout=0.1,\n",
    "                                                recurrent_dropout=0.5,\n",
    "                                                return_state=True)(encoder_outputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# 훈련 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "dec_inputs = layers.Input(shape=(None,))\n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_embedding = layers.Embedding(len(words), emb_dim)\n",
    "decoder_outputs = decoder_embedding(dec_inputs)\n",
    "\n",
    "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
    "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
    "decoder_lstm = layers.LSTM(h_size,\n",
    "                           dropout=0.1,\n",
    "                           recurrent_dropout=0.5,\n",
    "                           return_state=True,\n",
    "                           return_sequences=True)\n",
    "\n",
    "# initial_state를 인코더의 상태로 초기화\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# 훈련 모델 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 입력과 출력으로 함수형 API 모델 생성\n",
    "model = models.Model([enc_inputs, dec_inputs], decoder_outputs)\n",
    "\n",
    "# 학습 방법 설정\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDAb3Ed1YoLG"
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "#  예측 모델 인코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
    "encoder_model = models.Model(enc_inputs, encoder_states)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# 예측 모델 디코더 정의\n",
    "#--------------------------------------------\n",
    "\n",
    "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
    "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
    "decoder_state_input_h = layers.Input(shape=(h_size,))\n",
    "decoder_state_input_c = layers.Input(shape=(h_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
    "\n",
    "# 임베딩 레이어\n",
    "decoder_outputs = decoder_embedding(dec_inputs)\n",
    "\n",
    "# LSTM 레이어\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
    "                                                 initial_state=decoder_states_inputs)\n",
    "\n",
    "# 히든 상태와 셀 상태를 하나로 묶음\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 예측 모델 디코더 설정\n",
    "decoder_model = models.Model([dec_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7neWJ76dYsAz"
   },
   "outputs": [],
   "source": [
    "# 인덱스를 문장으로 변환\n",
    "def convert_index_to_text(indexs, vocabulary): \n",
    "    \n",
    "    sentence = ''\n",
    "    \n",
    "    # 모든 문장에 대해서 반복\n",
    "    for index in indexs:\n",
    "        if index == END_INDEX:\n",
    "            # 종료 인덱스면 중지\n",
    "            break;\n",
    "        if vocabulary.get(index) is not None:\n",
    "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
    "            sentence += vocabulary[index]\n",
    "        else:\n",
    "            # 사전에 없는 인덱스면 UNK 단어를 추가\n",
    "            sentence.extend([vocabulary[UNK_INDEX]])\n",
    "            \n",
    "        # 빈칸 추가\n",
    "        sentence += ' '\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "669stk8RYu5R",
    "outputId": "59c92497-00cd-4b88-94d9-6c2c60a24a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Epoch : 1\n",
      "accuracy : 0.9266666769981384\n",
      "loss : 0.35812312364578247\n",
      "맛있게 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 2\n",
      "accuracy : 0.968999981880188\n",
      "loss : 0.14514704048633575\n",
      "가세 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 3\n",
      "accuracy : 0.9739999771118164\n",
      "loss : 0.08765653520822525\n",
      "가세 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 4\n",
      "accuracy : 0.9783333539962769\n",
      "loss : 0.06297517567873001\n",
      "가세 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 5\n",
      "accuracy : 0.9853333234786987\n",
      "loss : 0.044016480445861816\n",
      "가세 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 6\n",
      "accuracy : 0.9919999837875366\n",
      "loss : 0.027679210528731346\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 7\n",
      "accuracy : 0.9953333139419556\n",
      "loss : 0.017140144482254982\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 8\n",
      "accuracy : 0.996999979019165\n",
      "loss : 0.011556596495211124\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 9\n",
      "accuracy : 0.9990000128746033\n",
      "loss : 0.005027387291193008\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 10\n",
      "accuracy : 0.999666690826416\n",
      "loss : 0.0017524176510050893\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 11\n",
      "accuracy : 1.0\n",
      "loss : 0.0006122245686128736\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 12\n",
      "accuracy : 0.9990000128746033\n",
      "loss : 0.001641127746552229\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 13\n",
      "accuracy : 1.0\n",
      "loss : 0.00019004421483259648\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 14\n",
      "accuracy : 0.999666690826416\n",
      "loss : 0.0008484653662890196\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 15\n",
      "accuracy : 1.0\n",
      "loss : 0.00014795167953707278\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 16\n",
      "accuracy : 0.999666690826416\n",
      "loss : 0.001423284295015037\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 17\n",
      "accuracy : 1.0\n",
      "loss : 2.6036621420644224e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 18\n",
      "accuracy : 1.0\n",
      "loss : 1.404542854288593e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 19\n",
      "accuracy : 1.0\n",
      "loss : 2.56245239143027e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "Total Epoch : 20\n",
      "accuracy : 1.0\n",
      "loss : 8.548993719159625e-06\n",
      "여행 은 언제나 좋죠 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 에폭 반복\n",
    "for epoch in range(20):\n",
    "    print('Total Epoch :', epoch + 1)\n",
    "\n",
    "    # 훈련 시작\n",
    "    history = model.fit([x_encoder, x_decoder],\n",
    "                        y_decoder,\n",
    "                        epochs=100,\n",
    "                        batch_size=64,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # 정확도와 손실 출력\n",
    "    print('accuracy :', history.history['accuracy'][-1])\n",
    "    print('loss :', history.history['loss'][-1])\n",
    "    \n",
    "    # 문장 예측 테스트\n",
    "    # (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n",
    "    input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
    "    input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
    "    results = model.predict([input_encoder, input_decoder])\n",
    "    \n",
    "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "    # 1축을 기준으로 가장 높은 값의 위치를 구함\n",
    "    indexs = np.argmax(results[0], 1) \n",
    "    \n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwJGM_ABYxEO"
   },
   "outputs": [],
   "source": [
    "# 예측을 위한 입력 생성\n",
    "def make_predict_input(sentence):\n",
    "\n",
    "    sentences = []\n",
    "    sentences.append(sentence)\n",
    "    sentences = pos_tag(sentences)\n",
    "    input_seq = convert_text_to_index(sentences, word_to_index, enc_input)\n",
    "    \n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJgBsvDYYyvS"
   },
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "def generate_text(input_seq):\n",
    "    \n",
    "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
    "    states = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 목표 시퀀스 초기화\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # 목표 시퀀스의 첫 번째에 <SOS> 태그 추가\n",
    "    target_seq[0, 0] = STA_INDEX\n",
    "    \n",
    "    # 인덱스 초기화\n",
    "    indexs = []\n",
    "    \n",
    "    # 디코더 타임 스텝 반복\n",
    "    while 1:\n",
    "        # 디코더로 현재 타임 스텝 출력 구함\n",
    "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
    "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
    "                                                [target_seq] + states)\n",
    "\n",
    "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
    "        index = np.argmax(decoder_outputs[0, 0, :])\n",
    "        indexs.append(index)\n",
    "        \n",
    "        # 종료 검사\n",
    "        if index == END_INDEX or len(indexs) >= max_len:\n",
    "            break\n",
    "\n",
    "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = index\n",
    "        \n",
    "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
    "        states = [state_h, state_c]\n",
    "\n",
    "    # 인덱스를 문장으로 변환\n",
    "    sentence = convert_index_to_text(indexs, index_to_word)\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "Dt_eySPHY0dJ",
    "outputId": "2d3c1212-b761-4616-f3a5-83307c2fbfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[372, 366, 236, 244, 412, 183,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('3박4일 놀러가고 싶다')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "LGKwqd-PY11D",
    "outputId": "7baee97a-f36b-4a07-f1fc-8bc17391fe5e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'여행 은 언제나 좋죠 '"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "joK8S2AqY3r9",
    "outputId": "c0bfd67c-b4c4-4c39-ea56-5757ed434d1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[372, 366, 236, 153, 244, 412, 183,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장을 인덱스로 변환\n",
    "input_seq = make_predict_input('3박4일 같이 놀러가고 싶다')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "QiJ_ZyaXY5Tc",
    "outputId": "a0ad1572-bf99-4f0f-c339-9f7dd08ad13f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'여행 은 언제나 좋죠 '"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 모델로 텍스트 생성\n",
    "sentence = generate_text(input_seq)\n",
    "sentence"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Learning Spoons 6강 (seq2seq).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
